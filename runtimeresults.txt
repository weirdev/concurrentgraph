Matrix computation test:
Iterated outside data loading:
All in seconds
100 runs with n=10_000 mat*vec mul
GPU: 16
CPU-ST: 468

500 runs with n=5_000 mat*vec mul
GPU: 19
CPU-ST: 556


time per run
n=10_000:
GPU: 0.16
CPU-ST: 4.68

n=5_000
GPU: .038
CPU-ST: 1.112

x linear time, y quadratic time
GPU
10_000*x + 10_000^2*y = 0.16
5_000*x + 5_000^2*y = 0.038
x ~= 0
y ~= 1.68*10^(-9)

CPU-ST
10_000*x + 10_000^2*y = 4.68
5_000*x + 5_000^2*y = 1.112
x ~= 0
y ~= 4.912*10(-8)


Iterated inside data loading:
GPU test
100 iters, 10_000 size mat
Ran in 7 secs

100 iters, 15_000 size mat
Ran in 18 secs

CPU-ST test
100 iters, 10_000 size mat
Ran in 465 secs

100 iters, 15_000 size mat
Ran in 1065 secs

time per iter
GPU test
10_000 size mat
.07
15_000 size mat
.18

CPU-ST test
10_000 size mat
4.65
15_000 size mat
10.65

GPU test
(10_000^2)*x = .07 => x = 7*10^(-10)
(15_000^2)*x = .18 => x = 8*10^(-10)
7.5*10(-10) s / computation

CPU-ST test
(10_000^2)*x = 4.65 => x = 4.65*10^(-8)
(15_000^2)*x = 10.65 => x = 4.73*10^(-8)
4.69*10^(-8) / computation

~62.53x speedup from GPU

Simulation test:
CPU-ST
2372 dead
3060 infected
Ran in 83 secs

GPU
2374 dead
3037 infected
Ran in 16 secs

~5.188x speedup from GPU

GPU restriction test:
All matricies at sparsity 0.01
1_000 nodes, 100_000 iterations
GPU restriction factor = 1
Ran in 27 secs
GPU restriction factor = 2
Ran in 29 secs
GPU restriction factor = 3
Ran in 27 secs
GPU restriction factor = 4
Ran in 30 secs
(I believe that the issue here may be that computation is so fast that the 100_000 functin calls are taking up a signification portion of the test runtime)

10_000 nodes, 1_000 iterations
GPU restriction factor = 1
Ran in 313 secs
GPU restriction factor = 2
Ran in 759 secs
GPU restriction factor = 3
Ran in 1006 secs
GPU restriction factor = 4
Ran in 1297 secs